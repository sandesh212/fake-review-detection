{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX0kAIQiMWjR"
   },
   "source": [
    "#**USING LSTM AND GENAI TO CREATE FAKE REVIEW DETECTION AND FEEDBACK SYSTEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "0sfNX6h1kirk",
    "outputId": "75ccceb8-74ed-4710-dc65-e6cfe5646c8f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"fake_reviews_dataset.csv\")\n",
    "print(df.isnull().sum())\n",
    "df = df.rename(columns={\"text_\": \"review\"})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "yFxhD29nm9gT",
    "outputId": "8aeef9b9-9b31-4e57-ac64-581bbbd078a9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get counts for each rating value for both labels\n",
    "or_ratings = df[df['label'] == 'OR']['rating'].value_counts().sort_index()\n",
    "cg_ratings = df[df['label'] == 'CG']['rating'].value_counts().sort_index()\n",
    "\n",
    "# Setting the positions and width for the bars\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(or_ratings))\n",
    "\n",
    "# Plotting the bars\n",
    "bar1 = plt.bar(index, or_ratings.values, bar_width, color='blue', label='OR')\n",
    "bar2 = plt.bar(index + bar_width, cg_ratings.values, bar_width, color='green', label='CG')\n",
    "\n",
    "# Setting the title and labels\n",
    "plt.title('Distribution of Ratings by Label')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks(index + bar_width / 2, or_ratings.index)  # Positioning the x-labels in the center of the grouped bars\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxkVuqRPQ62p",
    "outputId": "d8f9cf92-627c-4f31-af45-a753f2b3d780"
   },
   "outputs": [],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSMVlqZcUKZ-",
    "outputId": "bc45ee2c-9556-493a-e1c0-9e7a5790838c"
   },
   "outputs": [],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "H09gD-7Xc5mq",
    "outputId": "514d9674-61da-45f9-9922-ab1857f36031"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get counts for each label in the dataset\n",
    "category_data = df[\"label\"].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(category_data.index, category_data.values, color='blue')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Distribution of Review Labels\")\n",
    "plt.xlabel(\"Review Labels\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "AgCGemBQOro-",
    "outputId": "3024903d-93a9-42e8-b53c-661c04d03f44"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "category_data = df[\"category\"].value_counts()\n",
    "plt.bar(category_data.index, category_data.values, color='blue')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3TcRVTIQg8p",
    "outputId": "061f248f-6fdc-441c-8657-0777bf6f8e35"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "reviews = df['review'].tolist()\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "# Convert text to sequences and pad them to a fixed length\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "\n",
    "max_sequence_length = 100\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Create a model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size + 1, output_dim=100, input_length=max_sequence_length))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data into training and testing sets (X and y are sequences and labels)\n",
    "X = sequences\n",
    "y = df['label'].values\n",
    "y = df['label'].map({'CG': 0, 'OR': 1}).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lstm = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Save the entire model to a .h5 file\n",
    "model.save('lstm_model.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQlZmkPPSMCf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m ensurepip\n",
    "pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfpwLtBySUqB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def predict_fake_review(review):\n",
    "# Tokenize and pad the review text\n",
    "    review_sequence = tokenizer.texts_to_sequences([review])\n",
    "    review_padded = pad_sequences(review_sequence, maxlen=max_sequence_length)\n",
    "\n",
    "    # Predict using the model\n",
    "    prediction = model.predict(review_padded)\n",
    "\n",
    "    # Check the prediction\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        return \"Genuine\"\n",
    "    else:\n",
    "        return \"Fake\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c_3rKHaSZ6F"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your API key\n",
    "import os\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Load from environment variable\n",
    "\n",
    "def query_gpt3_5_chat(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2HXVG7hSeLp"
   },
   "outputs": [],
   "source": [
    "def handle_customer_review(review):\n",
    "    review_type = predict_fake_review(review)\n",
    "    if review_type == \"Fake\":\n",
    "        return \"The review appears to be inauthentic.\"\n",
    "    else:\n",
    "        # If the review is genuine, get suggestions from GPT-3.5\n",
    "        prompt_for_gpt = f\"The following review seems genuine: '{review}'. Can you provide suggestions for improvement of the product?\"\n",
    "        response = query_gpt3_5_chat(prompt_for_gpt)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaEsROVfSfYE",
    "outputId": "3a2f1744-6d3d-4e33-aace-d93bf1f9777a"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_review_2 = \"This is one of the coolest screensavers I have ever seen, the fish move realistically, the environments look real, and the graphics are stunning.\"\n",
    "print(handle_customer_review(sample_review_2))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
